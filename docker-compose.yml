services:
  redis:
    image: redis:alpine
    container_name: redis
    restart: unless-stopped
    networks:
      - llm-net
    profiles:
      - prod

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - llm-net
    restart: unless-stopped
    environment:
      - DEFAULT_MODEL=${DEFAULT_MODEL:-gemma3}
    entrypoint: [ "/bin/sh", "-c" ]
    command:
      - |
        /bin/ollama serve &
        sleep 5
        ollama pull $$DEFAULT_MODEL
        wait
    # GPU Support (uncomment for NVIDIA environment)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  auth-service:
    build:
      context: ./auth
    container_name: auth-service
    ports:
      - "127.0.0.1:5001:5001"
    environment:
      - FLASK_APP=app.py
      - FLASK_RUN_PORT=5001
      - FLASK_RUN_HOST=0.0.0.0
      - FLASK_DEBUG=0
      - ADMIN_USER=${ADMIN_USER:-elmo.visuri@gmail.com}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-changeme}
      - TOKEN_EXPIRATION_HOURS=${TOKEN_EXPIRATION_HOURS:-1}
      - ALLOWED_DOMAINS=${ALLOWED_DOMAINS:-gapps.fi}
      - REDIS_URL=${REDIS_URL:-}
    volumes:
      - jwks_data:/app/keys
      - auth_data:/app/data
    networks:
      - llm-net

  llm-api:
    build:
      context: ./llm-api
    container_name: llm-api
    ports:
      - "5002:5000"
    environment:
      - FLASK_APP=app.py
      - FLASK_RUN_PORT=5000
      - FLASK_RUN_HOST=0.0.0.0
      - FLASK_DEBUG=0
      - OLLAMA_HOST=http://ollama:11434
      - DEFAULT_MODEL=${DEFAULT_MODEL:-gemma3}
      - ALLOWED_USERS=${ALLOWED_USERS:-}
      - ALLOWED_DOMAINS=${ALLOWED_DOMAINS:-gapps.fi}
      - REDIS_URL=${REDIS_URL:-}
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-chatdb}
      - POSTGRES_HOST=postgres
    volumes:
      - jwks_data:/app/keys:ro
    networks:
      - llm-net
    depends_on:
      - ollama
      - auth-service
      - postgres

  postgres:
    image: postgres:18-alpine
    container_name: postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-postgres}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-postgres}
      - POSTGRES_DB=${POSTGRES_DB:-chatdb}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - llm-net

  chat-ui:
    build:
      context: ./chat-ui
      args:
        - VITE_API_BASE_URL=http://localhost:5002
        - VITE_AUTH_URL=http://localhost:5001
    container_name: chat-ui
    ports:
      - "8080:8080"
    environment:
      - PORT=8080
    networks:
      - llm-net
    depends_on:
      - llm-api

networks:
  llm-net:
    driver: bridge

volumes:
  ollama_data:
  jwks_data:
  auth_data:
  postgres_data:
